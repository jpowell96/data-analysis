Notes:
Data Taken From:
https://catalog.data.gov/dataset/fdic-failed-bank-list

https://medium.com/@jberry_33001/handling-missing-values-in-time-series-with-sql-a910b5f481fe 


Main Page:
https://fdic.gov/resources/resolutions/bank-failures/failed-bank-list/index.html
- Some values have commas within them. COPY might take care
of these by default, but not sure?
- Will banks have duplicate names?
denormalized:
- banks
id, name

- city
id, name
- state
id, name

-- Create the table
CREATE TABLE bank_failures (
id bigserial,
bank_name TEXT,
city TEXT,
state TEXT,
cert TEXT,
acquiring_institution TEXT,
closing_date DATE,
fund BIGINT
);

-- Copy data into the table
COPY bank_failures (
bank_name,
city,
state,
cert,
acquiring_institution,
closing_date,
fund
) FROM '/Users/jjpowell/projects/data-analysis/bank_failures/banklist.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', ESCAPE '"', ENCODING 'ASCII);

I had done some test inserts before realizing I had to specify FORMAT csv so I could correctly escape quote characters. I deleted old data from testing, but now I wanted to reset the sequence for my table. Postgres stores a sequence that keeps track of the current highest id for an autoincrement id. 

To find the sequence I did:
 select sequence_name  FROM information_schema.sequences;
https://www.postgresql.org/docs/current/infoschema-sequences.html
Which gave me me the name of the sequence for my table:
 bank_failures_id_seq

So I reset it with:
 ALTER sequence  bank_failures_id_seq RESTART

Now I imported my data for real but got this error: ERROR:  invalid byte sequence for encoding "UTF8": 0x96

It turns out that the hyphen character for one of the banks was a special character. I replaced it with a - character and that allowed me to import all the data


Normalizing the Data:
I want to try normalizing the data. I want to extract the 
banks, city, and state into their own tables.

States: 
SELECT DISTINCT state from bank_failures;
 CREATE TABLE state_dimension (
 	id serial,
 	state TEXT NOT NULL
 );
INSERT INTO state_dimension(state) SELECT DISTINCT state FROM bank_failures;

Cities:
SELECT DISTINCT city from bank_failures;
CREATE TABLE city_dimension (
        id serial,
        city TEXT NOT NULL UNIQUE
 );
 INSERT INTO city_dimension(city) SELECT DISTINCT city FROM bank_failures;

cert column = FDIC Certificate The FDIC Certificate ID is a unique number assigned to each depository institution by the Federal Deposit Insurance Corporation (FDIC).

-- Initially allow fdic_cert_num null until we can backfill the missing ones
I haven't add FK constraints because I know I need to do a backfill for acquiring institutions
but don't know if I'll have all of the data.

 CREATE TABLE bank_dimension (
 	id bigserial,
 	name TEXT NOT NULL,
 	fdic_cert TEXT,
 	city_id INT,
 	state_id INT
 );
Now that we have city, and state populated, I want to make a query to get all the failed banks
to populate the bank_dimension table.

SELECT bank_name, cert, c.id, s.id 
FROM bank_failures b  
	INNER JOIN state_dimension s ON b.state = s.state 
	INNER JOIN city_dimension c ON b.city = c.city;

INSERT INTO bank_dimension 
	SELECT bank_name, cert, c.id, s.id 
	FROM bank_failures b  
		INNER JOIN state_dimension s ON b.state = s.state 
		INNER JOIN city_dimension c ON b.city = c.city;
Note that this only populates the bank tables with banks that appear in the bank_name column.
There are also banks in the acquiring institution column, so I want to find out which 
banks in that column are.

Query to introspect table: SELECT column_name  FROM information_schema.columns WHERE table_name = 'bank_failures';

I want to see how many acquiring instituions are not in the bank_name column.
1. SELECT COUNT(DISTINCT acquiring_institution) FROM bank_failures; -- Find how many distinct ones there are
2. Find out how many there are excluding the bank names column:
SELECT COUNT(DISTINCT acquiring_institution) FROM (SELECT acquiring_institution FROM bank_failures EXCEPT SELECT bank_name FROM bank_failures) AS subquery;

3. Find all the acquiring institutions that were not later acquired
SELECT DISTINCT acquiring_institution FROM bank_failures EXCEPT SELECT DISTINCT bank_name FROM  bank_failures;

3a. export to csv
TODO: See if I can query the fdic api to get data on the remaining institutions:
Found a CSV dump of all the institutions in the FDIC, so I dumped those from
this link:
https://banks.data.fdic.gov/docs/#/api_endpoints

And I populated the bank_dimension table with those. 

3b. Populate the banks table with the acquiring banks

4. Do some time series analysis. Show failures by Year, Month
What were the failures by year, month:
 SELECT EXTRACT('YEAR' FROM closing_date) as acq_year, EXTRACT('MONTH' FROM closing_date) as acq_month, COUNT(*) as total_failures  FROM bank_failures GROUP BY acq_year, acq_month ORDER BY acq_year, acq_month;

 You'll notice from this query that we don't have a month for every year.
 To fix this, I made a month table with all the months Jan - Dec.

 I did a cross join on all the years from bank table and made a timescale table I used to query data:
 WITH all_years AS (SELECT DISTINCT EXTRACT(YEAR FROM closing_date) AS year FROM bank_failures),
 all_months AS (SELECT DISTINCT EXTRACT(MONTH FROM closing_date) as month FROM bank_failures),
 timescale AS (SELECT year, month FROM all_years CROSS JOIN all_months ORDER BY year, month ASC)

 Using this CTE, I could find the total closings across month-to-month, or year-over-year like this:

 SELECT year, month, COUNT(id) AS total_closings
 FROM timescale t LEFT JOIN bank_failures b
 ON t.year = EXTRACT(YEAR FROM b.closing_date)
    AND t.month = EXTRACT(MONTH FROM b.closing_date)
 WHERE t.year = 2000
 GROUP BY year , month    
 ORDER BY year ASC, month ASC;

Notice that I used COUNT(id) rather than COUNT(*). Because we use a left join,
columns that do not match the join condition have null values. To ensure I count banks that closed,
I need to COUNT(id) which will filter out the rows that had null ids.

I could add this CTE to the start of every query, but for efficiency, I wanted to make a materialized view of the time scale. A materialized view is a query that your database computes and saves the results for. That means that I can use the data from timescale without extra query costs from doing a CROSS JOIN every time. 

To create the materialized I ran:
CREATE MATERIALIZED VIEW IF NOT EXISTS timescale(year, month, month_name) AS (
	WITH all_years AS (SELECT DISTINCT EXTRACT(YEAR FROM closing_date) AS year FROM bank_failures),
 	all_months AS (SELECT DISTINCT EXTRACT(MONTH FROM closing_date) as month, TO_CHAR(closing_date, 'Month') as month_name FROM bank_failures)
 	SELECT year, month, month_name FROM all_years CROSS JOIN all_months ORDER BY year ASC, month ASC
)
WITH DATA; 

To double check the view, I query the information_schema for my database:
select * FROM pg_matviews where matviewname = 'timescale';
This displays the query for the materialized view.

Now I'm going to do some time series analysis. First, to show the bank failures by year:

SELECT year, COUNT(bank_name) as bank_failures 
FROM bank_failures LEFT JOIN timescale 
	ON EXTRACT('YEAR' from closing_date) = timescale.year
GROUP BY year 
ORDER BY year ASC;

This initial query is wrong because this would create 12 rows for each entry in the bank_failures table. That's because the JOIN is just on the year column. We need to match the granularity of the 
timescale table (year, month). To get an accurate number of failures per year:

SELECT year, COUNT(id) as bank_failures 
FROM bank_failures LEFT JOIN timescale 
	ON EXTRACT('YEAR' from closing_date) = timescale.year 
		AND EXTRACT('MONTH' from closing_date) = timescale.month
GROUP BY year 
ORDER BY year ASC;

I validaetd that this matched the summary on the FDIC page: https://www.fdic.gov/bank/historical/bank/

Now, we can do a few other queries. First I'll add columns for lag, lead, and running total:

-- Current year with previous year stuff
WITH closings_by_year AS (
SELECT year, 
	   COUNT(id) as closings
FROM bank_failures LEFT JOIN timescale 
	ON EXTRACT('YEAR' from closing_date) = timescale.year 
		AND EXTRACT('MONTH' from closing_date) = timescale.month
GROUP BY year 
ORDER BY year ASC)
SELECT year, closings, 
LAG(closings) OVER (ORDER BY year ASC) as previous_year
FROM closings_by_year;

-- Current year with a running total
WITH closings_by_year AS (
SELECT year, 
	   COUNT(id) as closings
FROM bank_failures LEFT JOIN timescale 
	ON EXTRACT('YEAR' from closing_date) = timescale.year 
		AND EXTRACT('MONTH' from closing_date) = timescale.month
GROUP BY year 
ORDER BY year ASC)
SELECT year, closings, 
SUM(closings) OVER (ORDER BY year ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as running_total
FROM closings_by_year;

5. Show failures by year, previous_year, next year with lag() and lead()
-- Current year with year over year change
WITH closings_by_year AS (
SELECT year, 
	   COUNT(id) as closings
FROM bank_failures LEFT JOIN timescale 
	ON EXTRACT('YEAR' from closing_date) = timescale.year 
		AND EXTRACT('MONTH' from closing_date) = timescale.month
GROUP BY year 
ORDER BY year ASC),

change_by_year AS (SELECT year, 
closings, 
LAG(closings) OVER (ORDER BY year ASC) as previous_year,
LEAD(closings) OVER (ORDER BY year ASC) as next_year
FROM closings_by_year)

SELECT year,
	   closings,
	   previous_year,
	   ROUND(COALESCE(closings :: NUMERIC / NULLIF(previous_year, 0) :: NUMERIC, 0) * 100 , 2) AS YoYChange
FROM change_by_year;

6. Use a recursive query to look for chains of acquisitions
 (test out by making a basic parent/child table and then apply this to the acquisitions table) Or make an ownership table

I'm also curious about which banks are acquiring each other. Let's ask:
SELECT acquiring_institution, COUNT(*) AS acquisitions 
FROM bank_failures 
GROUP BY acquiring_institution 
ORDER BY acquisitions DESC;

-- Group acquisitions:

-- Do some parent child analysis on the table